{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobias-hoepfl/Digital-Organizations-SE/blob/main/assignments/assignment_3_Hoepfl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "fastbook.setup_book()"
      ],
      "metadata": {
        "id": "HhmY7I5M8VJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49197527-1789-45d0-9634-13c4a8fbe1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Artificial Neural Networks\n",
        "\n",
        "Please read the introdcution of neuronal networks of the book *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow*, p. 299-316.\n",
        "\n",
        "Why have neural networks, even though they were invented early on, only now caught on?\n",
        "\n",
        "<b>Answer:</b>\n",
        "\n",
        "- Larger amounts of data available than before: this has enabled neural networks to outperform other machine learning techniques for complex problems.\n",
        "- Increased computing power: thanks to Moore's Law and the gaming industry, it is now possible to train large neural networks in a reasonable amount of time. Cloud platforms have made this power accessible to everyone.\n",
        "- Improvements in training algorithms have had a huge impact on ANNs\n",
        "- Theoretical limitations of ANNs, such as local optima, have proven to be less problematic in practice, particularly for larger neural networks.\n",
        "- ANNs are in a virtuous circle of funding and progress: amazing products based on them regularly make headline news (e.g. ChatGPT), attract more attention and funding, which results in further progress and even better products.\n",
        "\n",
        "<br>\n",
        "\n",
        "What is a percepton and a threshold logic unit (TLU)? Try to define a linear function and a step function of your choice, use some values of your choice and explain what might be the result of the percepton. (maybe using max. two TLU's)\n",
        "\n",
        "<b>Answer:</b>\n",
        "\n",
        "TLU:\n",
        "- Threshold logic unit\n",
        "- It takes one or more inputs and produces a single output by taking the weighted sum of its inputs and passing it through a step function.\n",
        "- The step function can be a heaviside function or a sign function for example.\n",
        "- Can be used as a simple binary classifier\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "Perceptron:\n",
        "- A perceptron is a simple type of neural network unit invented by Frank Rosenblatt in 1957.\n",
        "- Composed of multiple TLUs organized in a single layer (called the output layer). Every TLU is connected to the input layer.\n",
        "- The perceptron can be trained using an algorithm called the perceptron learning rule (see book). The rule works as follows: When an output neuron produces an incorrect prediction, the connection weights from the inputs that would have led to the correct prediction are strengthened. This means that the perceptron learning rule adjusts the weights of the inputs based on the difference between the actual output and the desired output, in order to minimize the error.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Example for Perceptron (consisting of two TLUs):\n",
        "\n",
        "- Two inputs: x<sub>1</sub> and x<sub>2</sub>\n",
        "- Two TLUs with different linear functions z<sub>1</sub> and z<sub>2</sub>:\n",
        "  - z<sub>1</sub> = 2x<sub>1</sub> - x<sub>2</sub> + 3\n",
        "  - z<sub>2</sub> = x<sub>1</sub> - x<sub>2</sub> - 10\n",
        "\n",
        "- Both have a heavide step function (see the formula in the book)\n",
        "- Example values:\n",
        "  - x<sub>1</sub> = 2 and x<sub>2</sub> = 2 \n",
        "   - -> z<sub>1</sub> = 5 -> heaviside(z<sub>1</sub>) = 1\n",
        "   - -> z<sub>2</sub> = -14 -> heaviside(z<sub>2</sub>) = 0\n",
        "  - x<sub>1</sub> = 50 and x<sub>2</sub> = 0 \n",
        "   - -> z<sub>1</sub> = 103 -> heaviside(z<sub>1</sub>) = 1\n",
        "   - -> z<sub>2</sub> = 40 -> heaviside(z<sub>2</sub>) = 1\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "What is a fully connected layer and a output layer?\n",
        "\n",
        "<b>Answer:</b>\n",
        "- Fully connected layer: every TLU is connected to every input (=dense layer)\n",
        "- Output layer: Layer that produces the final output (in case there is only one layer, this is also the output layer)\n",
        "\n",
        "<br>\n",
        "\n",
        "Why can we easily combine the equations of multiple instances into a fully connected layer?\n",
        "\n",
        "<b>Answer:</b>\n",
        "Because linear algebra allows to work with vectors and matrices. This way we can do forward/backward propagation for many instances at the same time.\n",
        "\n",
        "<br>\n",
        "\n",
        "What problem did Marvin Minsky and Seymour Paper highlight that perceptrons could not solve? What is a possible solution?\n",
        "\n",
        "<b>Answer:</b>\n",
        "\n",
        "They noted that perceptrons are unable to solve specific problems. This can also be the case for simple problems, e.g. the XOR-problem (see the graph in the book). Stacking multiple perceptrons, i.e. adding another layer, makes it possible to solve some of these problems.\n",
        "\n",
        "<br>\n",
        "\n",
        "What is a deep neuronal network? What are hidden layers? What means feedforward neural network (FNN).\n",
        "\n",
        "<b>Answer:</b>\n",
        "- Hidden layers are additional layers that are not output layers. A neural network can consist of many of these.\n",
        "- A neural network that contains a lot of hidden layers is called a deep neural network (although the exact number depends on the definition)\n",
        "- FNN: If the signal flows only in one direction from input layer to output layer\n",
        "\n",
        "<br>\n",
        "\n",
        "Try to explain how backpropagation works! (In Addition, you can have a look to the following example, which tries manually to compute the backprogation of a simple linear network. https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/ OR you can also read through the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy))\n",
        "\n",
        "\n",
        "<b>Answer:</b>\n",
        "\n",
        "- Backpropagation handles a small chunk of the training data at a time, and repeats this process multiple times on the entire training set.\n",
        "- The input data is fed into the input layer of the network. Then, the network calculates the output of the neurons in each hidden layer, continuing until the output layer is reached. This forward pass keeps all the intermediate calculations.\n",
        "- The network's output error is measured using a loss function.\n",
        "- The algorithm figures out how much each output bias and connection to the output layer contributed to the error, then works backward through each layer until it gets to the input layer.\n",
        "- The backward pass efficiently measures the error gradient across all the connection weights and biases in the network by propagating the error gradient backward through the network.\n",
        "- Lastly, the algorithm uses the error gradients to adjust all the connection weights in the network through a process called gradient descent.\n",
        "\n",
        "<br>\n",
        "\n",
        "Why do we need activation functions, wouldn't it be easier just using linear functions?\n",
        "\n",
        "<b>Answer:</b>\n",
        "\n",
        "When chaining multiple linear functions, one always ends up with a linear function again. But many complex problems cannot be solved using linear functions. On the other hand, Artificial Neural Networks using non-linear activation functions make it possible to express any continuous function.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "## Ideas for the learning portfolio: \n",
        "\n",
        "1) For example, you could train a single TLU to classify iris flowers based on petal length and width in the !!!pyTorch!! environment.\n",
        "\n",
        "2) You could add to our king county housepricing ML project a neuronal network and compare it to the other models. "
      ],
      "metadata": {
        "id": "_Rdj49uwjuoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "4tF8YDV3T91n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A traditional approach: training a digit classifier and learning pyTorch tensors.\n",
        "\n",
        "For this assignment, I ask you to read the Google Colab [04_mnist_basics.ipynb](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb#scrollTo=t1DK6o-gckCy) to the beginning of the chapter *Stochastic Gradient Descent (SGD)*. \n",
        "\n",
        "First, try to summarize what we know about pyTorch tensors by trying to predict whether we have a 1 or a 7 in the MNIST dataset using a traditional rule-based programming approach. Therefore use pyTorch tensors for the entire tasks and fulfill the following steps:\n",
        "\n",
        "1) Randomly split the MNIST dataset (1 and 7) into a training dataset and a test dataset in a ratio of 80:20.\n",
        "\n",
        "2) Instead of using an optimal 1 or 7 with the mean over the training dataset, try to calculate the sum of the distances to all instances in the training set for each instance in the test dataset. You can use the L2 norm. \n",
        "\n",
        "3) For each instance in the test set, decide if it is a 1 or 7 and calculate the precision.\n",
        "\n",
        "Do we get a similar good result?\n"
      ],
      "metadata": {
        "id": "h6OwXNEeed93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FastAI MNIST_SAMPLE does only have 3s and 7s available, so the full MNIST (or alternatively MNIST) dataset needs to be loaded (which has a path structure that is a bit different)\n",
        "path = untar_data(URLs.MNIST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "m6OOaje71HHN",
        "outputId": "7fd9f213-4ac2-4aac-888c-ebfa30807e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:02&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path.BASE_PATH = path"
      ],
      "metadata": {
        "id": "2Ln1nvNe1SV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6151QgE1cMv",
        "outputId": "7a5215f4-6268-4a8d-b065-88af45815db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('testing'),Path('training')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The subtask \"Randomly split the MNIST dataset (1 and 7) into a training dataset and a test dataset in a ratio of 80:20\" not entirely clear.\n",
        "# Splitting in training and test data has already been done, so in my opinion it does not make sense to split the test data again"
      ],
      "metadata": {
        "id": "utVEEtqq1-Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get fastAI lists for ones and sevens\n",
        "ones = (path/'training'/'1').ls().sorted()\n",
        "sevens = (path/'training'/'7').ls().sorted()"
      ],
      "metadata": {
        "id": "os8yG3CF2T_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#only 1000 elements are taken to make code faster\n",
        "ones = ones[0:999]\n",
        "sevens = sevens[0:999]"
      ],
      "metadata": {
        "id": "ShjcsjfL30w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#look at image of the first one in the dataset\n",
        "im1_path = ones[1]\n",
        "im1 = Image.open(im1_path)\n",
        "im1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "9JpvO-j_7zQs",
        "outputId": "40723b47-3ad1-4801-c252-a47ffc6cd3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAoElEQVR4nGNgGASA98pfCxibCV2SW+N/ME6dOX/+6OKUfPnnMCcuOdO/f/zhHHQ77ZkYv+GUZPj36ApOK4//XYdTTund3xickhP+vODAJef29+9dXHKcs//8iccl6ffnzwpkPopXghkYHuLSWP/lzyUxXJKn/v5NwiUX//fPbkEIk1UQXfLZ31vCUCa7JJqcz4+/BbgMZeB8sQVn4NARAABosDHlWlHdewAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hrrgv9OVebAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f53c666-8dee-462c-a214-72f74cbf3977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([999, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Create tensors for ones and sevens and stack them, to have a tensor for each label instead of a list of tensors\n",
        "one_tensors = [tensor(Image.open(o)) for o in ones]\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "\n",
        "stacked_ones = torch.stack(one_tensors).float()/255\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "\n",
        "#Check the resulting shape\n",
        "stacked_sevens.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Also transform test data, so they have the same data type and shape\n",
        "ones_testing = (path/'testing'/'1').ls().sorted()\n",
        "sevens_testing = (path/'testing'/'7').ls().sorted()\n",
        "\n",
        "one_tensors_testing = [tensor(Image.open(o)) for o in ones_testing]\n",
        "seven_tensors_testing = [tensor(Image.open(o)) for o in sevens_testing]\n",
        "\n",
        "#only take 200 elements to make code faster\n",
        "stacked_ones_testing = (torch.stack(one_tensors_testing).float()/255)[0:199]\n",
        "stacked_sevens_testing = (torch.stack(seven_tensors_testing).float()/255)[0:199]"
      ],
      "metadata": {
        "id": "WpEw5U84Qms7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Algorithm: First only on one instance of 1\n",
        "\n",
        "inst_1 = stacked_ones[1]\n",
        "inst_2 = stacked_ones[2]\n",
        "\n",
        "#Calculate l2-distance between two instances\n",
        "F.mse_loss(inst_1, inst_2).sqrt()\n",
        "print(F.mse_loss(inst_1, inst_2).sqrt())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikUPOkGw8i1b",
        "outputId": "237c7b9b-9096-4d80-a0b2-8f632f4f7f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2643)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate sum of the l2-distance to all other instances that are ones in the data set\n",
        "#Using list comprehensions\n",
        "def sum_of_distances(instance, training_tensor):\n",
        "  list_distances = [(F.mse_loss(instance, t).sqrt()).item() for t in training_tensor]\n",
        "  sum_distances = sum(list_distances)\n",
        "  return sum_distances\n",
        "\n",
        "print(sum_of_distances(inst_2, stacked_ones))\n",
        "print(sum_of_distances(inst_2, stacked_sevens))\n",
        "\n",
        "#as expected: is higher for ones than for sevens (correct classification for this instance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lomMv9m4QuTV",
        "outputId": "05643a9a-b0ef-4c6e-8adf-79b4677df4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236.24830117821693\n",
            "315.3656358718872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sum_of_distances: broadcasting does not seem to work if both arguments are tensors (would be the case in sum_of_distances), so a loop has to be written -> Is there a more efficient way using tensors directly?\n",
        "def distances(instances):\n",
        "  distances_to_ones = [sum_of_distances(instance, stacked_ones) for instance in instances]\n",
        "  distances_to_sevens = [sum_of_distances(instance, stacked_sevens) for instance in instances]\n",
        "  return tensor(distances_to_ones), tensor(distances_to_sevens)"
      ],
      "metadata": {
        "id": "nCyQJzZzPQ_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances_of_ones = distances(stacked_ones_testing)\n",
        "distances_of_sevens = distances(stacked_sevens_testing)"
      ],
      "metadata": {
        "id": "mB0X0IyuWuI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances_of_ones_to_ones, distances_of_ones_to_sevens = distances_of_ones\n",
        "distances_of_sevens_to_ones, distances_of_sevens_to_sevens = distances_of_sevens\n",
        "\n",
        "predict_ones_correctly = distances_of_ones_to_ones < distances_of_ones_to_sevens\n",
        "predict_sevens_correctly = distances_of_sevens_to_sevens < distances_of_sevens_to_ones\n",
        "#accuracy for ones\n",
        "print(predict_ones_correctly.float().mean())\n",
        "\n",
        "#accuracy for sevens\n",
        "print(predict_sevens_correctly.float().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7o6Qje-Wkw0",
        "outputId": "e76f153e-c64b-4229-e80f-3ee15f65caac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n",
            "tensor(0.7035)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- Accuracy for ones (100%) is higher than for sevens (70%) in the test set used\n",
        "- Further investigation should be made why there is such a discrepancy\n",
        "- Algorithm is much more runtime-intense (because the distance to all other instances has to be calculated) -> therefore only a subset of the data was taken\n",
        "- 1 vs. 7 as compared to 3 vs. 7 (in the example).\n",
        "- So it is difficult to directly compare the two algorithms"
      ],
      "metadata": {
        "id": "o_3jDGua3CkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent (SGD)\n",
        "\n",
        "For this exercise I ask you to read the chapter Stochastic Gradient Descent (SGD) from the Google Colab 04_mnist_basics.ipynb in paralell. The chapter starts with a single TLU, compare p. 304 in \"Hands on Machine Learning\". Go through all 7 steps which are an easy example of how Stochastic Gradient Descent works.\n",
        "\n",
        "Our goal is to train a single TLU, which can decide if one number is larger then the other one. Therefore we create 100 random pairs with pyTorch and create a target vector which is eather 1 or 0.\n"
      ],
      "metadata": {
        "id": "ETcE9B9rdcEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((100, 2))\n",
        "y = torch.where(x[:,0] > x[:,1], 1.0, 0.0)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "17qLyDnbpSbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e1a816-ef83-44be-cb04-7d8ebe143ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.9269e+00,  1.4873e+00],\n",
            "        [ 9.0072e-01, -2.1055e+00],\n",
            "        [ 6.7842e-01, -1.2345e+00],\n",
            "        [-4.3067e-02, -1.6047e+00],\n",
            "        [-7.5214e-01,  1.6487e+00],\n",
            "        [-3.9248e-01, -1.4036e+00],\n",
            "        [-7.2788e-01, -5.5943e-01],\n",
            "        [-7.6884e-01,  7.6245e-01],\n",
            "        [ 1.6423e+00, -1.5960e-01],\n",
            "        [-4.9740e-01,  4.3959e-01],\n",
            "        [-7.5813e-01,  1.0783e+00],\n",
            "        [ 8.0080e-01,  1.6806e+00],\n",
            "        [ 1.2791e+00,  1.2964e+00],\n",
            "        [ 6.1047e-01,  1.3347e+00],\n",
            "        [-2.3162e-01,  4.1759e-02],\n",
            "        [-2.5158e-01,  8.5986e-01],\n",
            "        [-1.3847e+00, -8.7124e-01],\n",
            "        [-2.2337e-01,  1.7174e+00],\n",
            "        [ 3.1888e-01, -4.2452e-01],\n",
            "        [ 3.0572e-01, -7.7459e-01],\n",
            "        [-1.5576e+00,  9.9564e-01],\n",
            "        [-8.7979e-01, -6.0114e-01],\n",
            "        [-1.2742e+00,  2.1228e+00],\n",
            "        [-1.2347e+00, -4.8791e-01],\n",
            "        [-9.1382e-01, -6.5814e-01],\n",
            "        [ 7.8024e-02,  5.2581e-01],\n",
            "        [-4.8799e-01,  1.1914e+00],\n",
            "        [-8.1401e-01, -7.3599e-01],\n",
            "        [-1.4032e+00,  3.6004e-02],\n",
            "        [-6.3477e-02,  6.7561e-01],\n",
            "        [-9.7807e-02,  1.8446e+00],\n",
            "        [-1.1845e+00,  1.3835e+00],\n",
            "        [ 1.4451e+00,  8.5641e-01],\n",
            "        [ 2.2181e+00,  5.2317e-01],\n",
            "        [ 3.4665e-01, -1.9733e-01],\n",
            "        [-1.0546e+00,  1.2780e+00],\n",
            "        [-1.7219e-01,  5.2379e-01],\n",
            "        [ 5.6622e-02,  4.2630e-01],\n",
            "        [ 5.7501e-01, -6.4172e-01],\n",
            "        [-2.2064e+00, -7.5080e-01],\n",
            "        [ 1.0868e-02, -3.3874e-01],\n",
            "        [-1.3407e+00, -5.8537e-01],\n",
            "        [ 5.3619e-01,  5.2462e-01],\n",
            "        [ 1.1412e+00,  5.1644e-02],\n",
            "        [ 7.4395e-01, -4.8158e-01],\n",
            "        [-1.0495e+00,  6.0390e-01],\n",
            "        [-1.7223e+00, -8.2777e-01],\n",
            "        [ 1.3347e+00,  4.8354e-01],\n",
            "        [-2.5095e+00,  4.8800e-01],\n",
            "        [ 7.8459e-01,  2.8647e-02],\n",
            "        [ 6.4076e-01,  5.8325e-01],\n",
            "        [ 1.0669e+00, -4.5015e-01],\n",
            "        [-1.8527e-01,  7.5276e-01],\n",
            "        [ 4.0476e-01,  1.7847e-01],\n",
            "        [ 2.6491e-01,  1.2732e+00],\n",
            "        [-1.3109e-03, -3.0360e-01],\n",
            "        [-1.4570e+00, -1.0234e-01],\n",
            "        [-5.9915e-01,  4.7706e-01],\n",
            "        [ 7.2618e-01,  9.1152e-02],\n",
            "        [-3.8907e-01,  5.2792e-01],\n",
            "        [-1.2685e-02,  2.4084e-01],\n",
            "        [ 1.3254e-01,  7.6424e-01],\n",
            "        [ 1.0950e+00,  3.3989e-01],\n",
            "        [ 7.1997e-01,  4.1141e-01],\n",
            "        [ 1.9312e+00,  1.0119e+00],\n",
            "        [-1.4364e+00, -1.1299e+00],\n",
            "        [-1.3603e-01,  1.6354e+00],\n",
            "        [ 6.5474e-01,  5.7600e-01],\n",
            "        [ 1.1415e+00,  1.8565e-02],\n",
            "        [-1.8058e+00,  9.2543e-01],\n",
            "        [-3.7534e-01,  1.0331e+00],\n",
            "        [-6.8665e-01,  6.3681e-01],\n",
            "        [-9.7267e-01,  9.5846e-01],\n",
            "        [ 1.6192e+00,  1.4506e+00],\n",
            "        [ 2.6948e-01, -2.1038e-01],\n",
            "        [-7.3280e-01,  1.0430e-01],\n",
            "        [ 3.4875e-01,  9.6759e-01],\n",
            "        [-4.6569e-01,  1.6048e+00],\n",
            "        [-2.4801e+00, -4.1754e-01],\n",
            "        [-1.1955e+00,  8.1234e-01],\n",
            "        [-1.9006e+00,  2.2858e-01],\n",
            "        [ 2.4859e-02, -3.4595e-01],\n",
            "        [ 2.8683e-01, -7.3084e-01],\n",
            "        [ 1.7482e-01, -1.0939e+00],\n",
            "        [-1.6022e+00,  1.3529e+00],\n",
            "        [ 1.2888e+00,  5.2295e-02],\n",
            "        [-1.5469e+00,  7.5671e-01],\n",
            "        [ 7.7552e-01,  2.0265e+00],\n",
            "        [ 3.5818e-02,  1.2059e-01],\n",
            "        [-8.0566e-01, -2.0758e-01],\n",
            "        [-9.3195e-01, -1.5910e+00],\n",
            "        [-1.1360e+00, -5.2260e-01],\n",
            "        [-1.5933e-01, -4.2494e-01],\n",
            "        [ 9.4423e-01, -1.8493e-01],\n",
            "        [ 1.0608e+00,  2.0830e-01],\n",
            "        [-5.7785e-01,  3.2546e-01],\n",
            "        [ 2.6178e-01, -7.5993e-01],\n",
            "        [-2.0461e+00, -1.5295e+00],\n",
            "        [ 4.0487e-01,  6.3188e-01],\n",
            "        [ 3.1253e-01, -3.3502e-02]])\n",
            "tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
            "        0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
            "        1., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to create a function f that is a single TLU, meaning that it summarizes x with weights a, b, c:\n",
        "\n",
        "$ax_0+bx_1+c$\n",
        "\n",
        "In Addition we are using a *sigmoid()* function as step function.\n",
        "\n",
        "$f = \\text{sigmoid}(ax_0+bx_1+c)$"
      ],
      "metadata": {
        "id": "z267w4G48rxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, params):\n",
        "    a,b,c = params\n",
        "    return 1/(1+torch.exp(a*x[:,0] + b*x[:,1] + c))\n",
        "\n",
        "print(f(x, [3,-2,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NvBnCGoLPx",
        "outputId": "70b10eba-10e3-4ba4-b7ff-84059b640c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.1749e-02, 3.6575e-04, 4.0526e-03, 1.6624e-02, 9.8958e-01, 6.7246e-02, 5.1619e-01, 9.4435e-01, 1.9342e-03, 7.9760e-01, 9.6866e-01, 4.8971e-01, 9.5823e-02, 4.5961e-01, 4.4482e-01, 8.1373e-01,\n",
            "        8.0401e-01, 9.5709e-01, 5.7018e-02, 3.0285e-02, 9.9654e-01, 6.0756e-01, 9.9915e-01, 8.4917e-01, 6.0473e-01, 4.5451e-01, 9.4515e-01, 4.9251e-01, 9.6380e-01, 6.3220e-01, 9.5178e-01, 9.9513e-01,\n",
            "        2.6019e-02, 1.3478e-03, 8.0572e-02, 9.9116e-01, 6.3741e-01, 4.2134e-01, 1.7837e-02, 9.8398e-01, 1.5315e-01, 8.6428e-01, 1.7374e-01, 1.3121e-02, 1.4847e-02, 9.6631e-01, 9.2493e-01, 1.7344e-02,\n",
            "        9.9945e-01, 3.5693e-02, 1.4732e-01, 6.0533e-03, 7.4294e-01, 1.3501e-01, 6.7953e-01, 1.6752e-01, 9.5955e-01, 8.5215e-01, 4.7597e-02, 7.7260e-01, 3.8219e-01, 5.3267e-01, 2.6461e-02, 8.8098e-02,\n",
            "        8.4111e-03, 7.4068e-01, 9.3577e-01, 1.4037e-01, 1.2280e-02, 9.9811e-01, 8.9955e-01, 9.1162e-01, 9.7885e-01, 4.9436e-02, 9.7159e-02, 8.0329e-01, 4.7226e-01, 9.7357e-01, 9.9634e-01, 9.8539e-01,\n",
            "        9.9428e-01, 1.4598e-01, 3.4818e-02, 2.3839e-02, 9.9852e-01, 8.4769e-03, 9.9426e-01, 6.7404e-01, 2.9603e-01, 7.3142e-01, 2.0003e-01, 7.9620e-01, 2.0231e-01, 1.4737e-02, 2.2626e-02, 7.9971e-01,\n",
            "        3.5393e-02, 8.8890e-01, 2.7871e-01, 1.1872e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to our TLU function, we need a loss function. Your task is to implement a absolute difference loss function, $∑|x_i-y_i|$, which counts the number of wrong guesses."
      ],
      "metadata": {
        "id": "UBiKkGKx-jVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(preds, targets): return (abs(preds-targets)).mean()"
      ],
      "metadata": {
        "id": "cwzyy281wI7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to train your single TLU with the absolute difference loss function, use the following code. Choose an appropriate step weight `lr` and try to explain what is happing in each line."
      ],
      "metadata": {
        "id": "eGVNErmbvFxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** \n",
        "\n",
        "Explanation see comments in code"
      ],
      "metadata": {
        "id": "fcxZsd4XHphT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lr is chosen smaller (see fastAI) -> Combined with more iterations it provides good results (see next code chunk)\n",
        "lr = 0.5\n",
        "\n",
        "#parameters are initialized randomly\n",
        "params = torch.randn(3).requires_grad_()\n",
        "\n",
        "def apply_step(params, prn=True):\n",
        "    #calculate predictions\n",
        "    preds = f(x, params)\n",
        "    #calculate loss with function defined before\n",
        "    loss = mae(preds, y)\n",
        "    #calculate gradient\n",
        "    loss.backward()\n",
        "    #parameters are updated using the learning rate and the gradient\n",
        "    params.data -= lr * params.grad.data\n",
        "    params.grad = None\n",
        "    #Print parameters and current loss\n",
        "    if prn: print(params);print(loss.item())\n",
        "    return preds\n",
        "\n",
        "#We apply it 100 times (to account for smaller learning rate)\n",
        "for i in range(100): apply_step(params)"
      ],
      "metadata": {
        "id": "EB5TYTNmyO3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3302aa6d-f68b-425d-dcc7-46e564e4264a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.5397,  1.6738,  0.0187], requires_grad=True)\n",
            "0.3251832127571106\n",
            "tensor([-0.6037,  1.6825,  0.0261], requires_grad=True)\n",
            "0.31654122471809387\n",
            "tensor([-0.6668,  1.6903,  0.0329], requires_grad=True)\n",
            "0.30815181136131287\n",
            "tensor([-0.7291,  1.6972,  0.0394], requires_grad=True)\n",
            "0.3000248968601227\n",
            "tensor([-0.7903,  1.7034,  0.0454], requires_grad=True)\n",
            "0.2921690046787262\n",
            "tensor([-0.8505,  1.7090,  0.0511], requires_grad=True)\n",
            "0.28459101915359497\n",
            "tensor([-0.9095,  1.7140,  0.0564], requires_grad=True)\n",
            "0.2772960662841797\n",
            "tensor([-0.9674,  1.7186,  0.0614], requires_grad=True)\n",
            "0.2702873945236206\n",
            "tensor([-1.0241,  1.7227,  0.0661], requires_grad=True)\n",
            "0.26356640458106995\n",
            "tensor([-1.0795,  1.7266,  0.0705], requires_grad=True)\n",
            "0.2571326196193695\n",
            "tensor([-1.1337,  1.7303,  0.0746], requires_grad=True)\n",
            "0.2509838938713074\n",
            "tensor([-1.1867,  1.7338,  0.0784], requires_grad=True)\n",
            "0.24511656165122986\n",
            "tensor([-1.2383,  1.7373,  0.0820], requires_grad=True)\n",
            "0.23952539265155792\n",
            "tensor([-1.2887,  1.7407,  0.0854], requires_grad=True)\n",
            "0.23420406877994537\n",
            "tensor([-1.3378,  1.7441,  0.0886], requires_grad=True)\n",
            "0.22914482653141022\n",
            "tensor([-1.3857,  1.7476,  0.0916], requires_grad=True)\n",
            "0.22433920204639435\n",
            "tensor([-1.4323,  1.7512,  0.0944], requires_grad=True)\n",
            "0.21977770328521729\n",
            "tensor([-1.4777,  1.7549,  0.0970], requires_grad=True)\n",
            "0.21545037627220154\n",
            "tensor([-1.5218,  1.7588,  0.0995], requires_grad=True)\n",
            "0.21134664118289948\n",
            "tensor([-1.5648,  1.7628,  0.1018], requires_grad=True)\n",
            "0.20745570957660675\n",
            "tensor([-1.6066,  1.7670,  0.1040], requires_grad=True)\n",
            "0.2037666290998459\n",
            "tensor([-1.6473,  1.7714,  0.1061], requires_grad=True)\n",
            "0.20026840269565582\n",
            "tensor([-1.6870,  1.7761,  0.1080], requires_grad=True)\n",
            "0.19695021212100983\n",
            "tensor([-1.7255,  1.7809,  0.1099], requires_grad=True)\n",
            "0.19380144774913788\n",
            "tensor([-1.7631,  1.7859,  0.1116], requires_grad=True)\n",
            "0.19081182777881622\n",
            "tensor([-1.7996,  1.7912,  0.1133], requires_grad=True)\n",
            "0.18797144293785095\n",
            "tensor([-1.8353,  1.7966,  0.1148], requires_grad=True)\n",
            "0.18527084589004517\n",
            "tensor([-1.8700,  1.8023,  0.1163], requires_grad=True)\n",
            "0.18270103633403778\n",
            "tensor([-1.9038,  1.8082,  0.1177], requires_grad=True)\n",
            "0.1802535504102707\n",
            "tensor([-1.9368,  1.8142,  0.1191], requires_grad=True)\n",
            "0.1779203563928604\n",
            "tensor([-1.9689,  1.8205,  0.1204], requires_grad=True)\n",
            "0.17569394409656525\n",
            "tensor([-2.0003,  1.8269,  0.1216], requires_grad=True)\n",
            "0.17356735467910767\n",
            "tensor([-2.0310,  1.8335,  0.1228], requires_grad=True)\n",
            "0.17153400182724\n",
            "tensor([-2.0609,  1.8402,  0.1239], requires_grad=True)\n",
            "0.16958783566951752\n",
            "tensor([-2.0901,  1.8471,  0.1249], requires_grad=True)\n",
            "0.1677231639623642\n",
            "tensor([-2.1187,  1.8541,  0.1260], requires_grad=True)\n",
            "0.165934756398201\n",
            "tensor([-2.1466,  1.8613,  0.1269], requires_grad=True)\n",
            "0.1642177551984787\n",
            "tensor([-2.1740,  1.8686,  0.1279], requires_grad=True)\n",
            "0.16256766021251678\n",
            "tensor([-2.2007,  1.8761,  0.1288], requires_grad=True)\n",
            "0.16098028421401978\n",
            "tensor([-2.2269,  1.8836,  0.1296], requires_grad=True)\n",
            "0.15945178270339966\n",
            "tensor([-2.2525,  1.8912,  0.1304], requires_grad=True)\n",
            "0.1579785794019699\n",
            "tensor([-2.2777,  1.8990,  0.1312], requires_grad=True)\n",
            "0.15655732154846191\n",
            "tensor([-2.3023,  1.9068,  0.1320], requires_grad=True)\n",
            "0.1551850289106369\n",
            "tensor([-2.3265,  1.9148,  0.1327], requires_grad=True)\n",
            "0.15385879576206207\n",
            "tensor([-2.3501,  1.9228,  0.1334], requires_grad=True)\n",
            "0.1525760293006897\n",
            "tensor([-2.3734,  1.9309,  0.1341], requires_grad=True)\n",
            "0.1513342559337616\n",
            "tensor([-2.3962,  1.9390,  0.1347], requires_grad=True)\n",
            "0.1501312404870987\n",
            "tensor([-2.4186,  1.9472,  0.1354], requires_grad=True)\n",
            "0.14896488189697266\n",
            "tensor([-2.4406,  1.9555,  0.1360], requires_grad=True)\n",
            "0.1478332132101059\n",
            "tensor([-2.4623,  1.9638,  0.1365], requires_grad=True)\n",
            "0.14673446118831635\n",
            "tensor([-2.4835,  1.9722,  0.1371], requires_grad=True)\n",
            "0.14566689729690552\n",
            "tensor([-2.5044,  1.9806,  0.1376], requires_grad=True)\n",
            "0.14462894201278687\n",
            "tensor([-2.5250,  1.9891,  0.1381], requires_grad=True)\n",
            "0.14361917972564697\n",
            "tensor([-2.5452,  1.9976,  0.1386], requires_grad=True)\n",
            "0.14263619482517242\n",
            "tensor([-2.5651,  2.0061,  0.1391], requires_grad=True)\n",
            "0.14167872071266174\n",
            "tensor([-2.5847,  2.0147,  0.1395], requires_grad=True)\n",
            "0.14074558019638062\n",
            "tensor([-2.6041,  2.0233,  0.1400], requires_grad=True)\n",
            "0.1398356407880783\n",
            "tensor([-2.6231,  2.0319,  0.1404], requires_grad=True)\n",
            "0.13894787430763245\n",
            "tensor([-2.6418,  2.0405,  0.1408], requires_grad=True)\n",
            "0.13808126747608185\n",
            "tensor([-2.6603,  2.0491,  0.1412], requires_grad=True)\n",
            "0.13723494112491608\n",
            "tensor([-2.6785,  2.0578,  0.1415], requires_grad=True)\n",
            "0.1364079713821411\n",
            "tensor([-2.6964,  2.0665,  0.1419], requires_grad=True)\n",
            "0.13559959828853607\n",
            "tensor([-2.7141,  2.0752,  0.1422], requires_grad=True)\n",
            "0.13480906188488007\n",
            "tensor([-2.7316,  2.0839,  0.1425], requires_grad=True)\n",
            "0.1340356171131134\n",
            "tensor([-2.7488,  2.0926,  0.1428], requires_grad=True)\n",
            "0.13327859342098236\n",
            "tensor([-2.7658,  2.1013,  0.1431], requires_grad=True)\n",
            "0.1325373500585556\n",
            "tensor([-2.7826,  2.1100,  0.1434], requires_grad=True)\n",
            "0.13181127607822418\n",
            "tensor([-2.7992,  2.1187,  0.1437], requires_grad=True)\n",
            "0.13109979033470154\n",
            "tensor([-2.8155,  2.1274,  0.1439], requires_grad=True)\n",
            "0.13040240108966827\n",
            "tensor([-2.8317,  2.1361,  0.1442], requires_grad=True)\n",
            "0.1297185868024826\n",
            "tensor([-2.8476,  2.1448,  0.1444], requires_grad=True)\n",
            "0.12904781103134155\n",
            "tensor([-2.8634,  2.1535,  0.1446], requires_grad=True)\n",
            "0.12838968634605408\n",
            "tensor([-2.8790,  2.1621,  0.1448], requires_grad=True)\n",
            "0.1277437061071396\n",
            "tensor([-2.8944,  2.1708,  0.1450], requires_grad=True)\n",
            "0.12710949778556824\n",
            "tensor([-2.9097,  2.1795,  0.1452], requires_grad=True)\n",
            "0.1264866590499878\n",
            "tensor([-2.9247,  2.1881,  0.1454], requires_grad=True)\n",
            "0.1258748173713684\n",
            "tensor([-2.9396,  2.1968,  0.1456], requires_grad=True)\n",
            "0.12527363002300262\n",
            "tensor([-2.9544,  2.2054,  0.1457], requires_grad=True)\n",
            "0.12468275427818298\n",
            "tensor([-2.9690,  2.2140,  0.1459], requires_grad=True)\n",
            "0.12410184741020203\n",
            "tensor([-2.9834,  2.2226,  0.1460], requires_grad=True)\n",
            "0.12353059649467468\n",
            "tensor([-2.9977,  2.2312,  0.1461], requires_grad=True)\n",
            "0.12296877056360245\n",
            "tensor([-3.0118,  2.2398,  0.1463], requires_grad=True)\n",
            "0.12241598218679428\n",
            "tensor([-3.0258,  2.2483,  0.1464], requires_grad=True)\n",
            "0.12187206000089645\n",
            "tensor([-3.0396,  2.2568,  0.1465], requires_grad=True)\n",
            "0.12133672088384628\n",
            "tensor([-3.0533,  2.2653,  0.1466], requires_grad=True)\n",
            "0.12080968916416168\n",
            "tensor([-3.0669,  2.2738,  0.1466], requires_grad=True)\n",
            "0.12029075622558594\n",
            "tensor([-3.0804,  2.2823,  0.1467], requires_grad=True)\n",
            "0.11977969110012054\n",
            "tensor([-3.0937,  2.2908,  0.1468], requires_grad=True)\n",
            "0.11927629262208939\n",
            "tensor([-3.1069,  2.2992,  0.1469], requires_grad=True)\n",
            "0.11878032982349396\n",
            "tensor([-3.1200,  2.3076,  0.1469], requires_grad=True)\n",
            "0.11829160898923874\n",
            "tensor([-3.1329,  2.3160,  0.1470], requires_grad=True)\n",
            "0.11780994385480881\n",
            "tensor([-3.1458,  2.3244,  0.1470], requires_grad=True)\n",
            "0.11733514815568924\n",
            "tensor([-3.1585,  2.3327,  0.1470], requires_grad=True)\n",
            "0.1168670579791069\n",
            "tensor([-3.1711,  2.3410,  0.1471], requires_grad=True)\n",
            "0.11640547960996628\n",
            "tensor([-3.1836,  2.3493,  0.1471], requires_grad=True)\n",
            "0.11595027148723602\n",
            "tensor([-3.1960,  2.3576,  0.1471], requires_grad=True)\n",
            "0.115501269698143\n",
            "tensor([-3.2083,  2.3659,  0.1471], requires_grad=True)\n",
            "0.11505833268165588\n",
            "tensor([-3.2205,  2.3741,  0.1471], requires_grad=True)\n",
            "0.11462129652500153\n",
            "tensor([-3.2326,  2.3823,  0.1471], requires_grad=True)\n",
            "0.11419004201889038\n",
            "tensor([-3.2446,  2.3905,  0.1471], requires_grad=True)\n",
            "0.11376441270112991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a line of code that counts the number of wrong predictions, rounding your predictions with *round()*."
      ],
      "metadata": {
        "id": "h5_LNc1o_o2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = f(x, params)\n",
        "\n",
        "#0 means no difference (i.e. correct prediction)\n",
        "diff = preds.round()-y\n",
        "\n",
        "#transform to list to count occurences\n",
        "print(diff.tolist().count(0))\n",
        "print(diff.tolist().count(-1) + diff.tolist().count(1))\n",
        "\n",
        "#99% correct predictions!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE3K4CTCIOBw",
        "outputId": "686b8715-a79e-4065-a2ee-02ebc8b44b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "1\n"
          ]
        }
      ]
    }
  ]
}