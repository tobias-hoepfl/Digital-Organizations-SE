{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBwZQOlaszZSTNifQi7PaO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobias-hoepfl/Digital-Organizations-SE/blob/main/learning_portfolio/6_recommendation_system_theory_Hoepfl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical understanding:**\n",
        "\n",
        "Answers to selected questions on the fastAI chapter (https://www.kaggle.com/code/jhoward/collaborative-filtering-deep-dive/notebook)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Practical understanding:**\n",
        "\n",
        "see homework and code comments that I did in the corresponding assignment (assignment 7)\n"
      ],
      "metadata": {
        "id": "M8MwR-J-LVWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory"
      ],
      "metadata": {
        "id": "N_fNT5RJMj31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What problem does collaborative filtering solve?**\n",
        "\n",
        "Recommend specific items or products to a specific user.\n",
        "\n",
        "<br>\n",
        "\n",
        "**How does it solve it?**\n",
        "\n",
        "It analyzes the behaviour of other users and based on the similarities to them it tries make predictions for users who have not yet rated a specific item or product. \n",
        "\n",
        "This approach can be used by applying cosine similarity like was shown in the youtube-video recommended (https://www.youtube.com/watch?v=Fmtorg_dmM0&ab_channel=ritvikmath). \n",
        "\n",
        "The approach used in the fastAI course works with the intuition that there are hidden (latent) features that deterime what a user will most propably like.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Why might a collaborative filtering predictive model fail to be a very useful recommendation system?**\n",
        "\n",
        "- Sparsity of data\n",
        "- I need a lot of data to be able to start (this might not be available for a lot of items)\n",
        "- Some highly active users might introduce a bias\n",
        "- Especially on less popular items there might be hardly any data\n",
        "\n",
        "<br>\n",
        "\n",
        "**What does a crosstab representation of collaborative filtering data look like?**\n",
        "\n",
        "Like a matrix where the rows represent the users and the columns the items.\n",
        "\n",
        "<br>\n",
        "\n",
        "**What is a latent factor? Why is it \"latent\"?**\n",
        "\n",
        "It is not directly visible in the data, but describes the underlying structure (e.g. a tendency to likes horror movie)\n",
        "\n",
        "<br>\n",
        "\n",
        "**What is an embedding matrix?**\n",
        "\n",
        "Transforms the matrix described before in a look-up table for each item-user combination (denser than the sparse matrix)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Why do we need Embedding if we could use one-hot-encoded vectors for the same thing?**\n",
        "\n",
        "One-hot-encoding would transform every level to its own column, which we don't want. Therefor we use an embedding which can also display continuous features\n",
        "\n",
        "<br>\n",
        "\n",
        "**What does an embedding contain before we start training (assuming we're not using a pretrained model)?**\n",
        "\n",
        "It contains random initializations for the factors.\n",
        "\n",
        "<br>\n",
        "\n",
        "**What is the use of bias in a dot product model?**\n",
        "\n",
        "It helps us to account for the fact that some users inherently tend to give higher ratings or some items are inherently more popular.\n",
        "\n",
        "<br>\n",
        "\n",
        "**What is another name for weight decay?**\n",
        "\n",
        "L2-regularization\n",
        "\n",
        "Helps to prevent overfitting\n",
        "\n",
        "<br>\n",
        "\n",
        "**Write the equation for weight decay.**\n",
        "\n",
        "loss_with_wd = loss + wd * (parameters**2).sum()\n",
        "\n",
        "The normal loss is incremented by a \"punishing factor\" for the size of the parameters.\n",
        "\n",
        "<br>\n",
        "\n",
        "**What is the \"bootstrapping problem\" in collaborative filtering?**\n",
        "\n",
        "Give recommendations to new users or for new items\n",
        "\n",
        "<br>\n",
        "\n",
        "**How could you deal with the bootstrapping problem for new users? For new movies?**\n",
        "\n",
        "- Just give them the recommendation for an average user (e.g. overall popular movies)\n",
        "- Use other data (demographics, etc.) if available (is called metadata)\n",
        "\n",
        "<br>\n",
        "\n",
        "**What kind of model should we use if we want to add metadata about users and items, or information such as date and time, to a collaborative filtering model?**\n",
        "\n",
        "e.g. use a hybrid recommender system that combines collaborative filtering with content-based filtering or other methods"
      ],
      "metadata": {
        "id": "G6vF9fVdL3jQ"
      }
    }
  ]
}